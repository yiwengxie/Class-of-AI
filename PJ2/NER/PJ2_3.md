## PJ2_3 BiLSTM+CRF实现NER任务

### 总体思路：

建立一个包含嵌入层、双向LSTM层和CRF层的神经网络模型。首先是数据准备，将单词转换为数字表示。在嵌入层，将数字表示的单词输入嵌入层，将其转换为向量表示。在双向LSTM层，将嵌入层的结果输入到双向LSTM层中，以捕捉输入序列的上下文信息，双向LSTM可以分别从前后两个方向对输入序列进行处理，并输入每个未知的隐藏状态序列。在CRF层，对双向LSTM输出的标签序列进行建模和解码，主要考虑了标签之间的依赖关系，通过学习转移矩阵来获得最优标签序列。

### 代码实现：

代码定义了三个类`preprocess`和`BiLSTM_CRF`和`Trainer`，分别用来数据预处理、实现双向LSTM+CRF模型和训练该模型。

#### 类`Preprocess`如下：

​	`__init__`初始构造函数传入了：`train_file` 、`test_file` 和  `language`三个参数以便针对不同的语言的数据集读取需求。

​	`read`读取函数完成了数据的读取和预处理，打开文件夹进行读取，并将文件中的文字和标签分别放入`words_train`和`labels_train`两个二维列表中，该列表中的每一个列表代表在数据集中用空行（`\n`）隔开的一个完整的句子。

​	`toidx`函数将文本数据转换为索引序列，首先建立`word2idx`和`tag2idx`两个字典，储存单词和标签的索引，目的是将文本数据转换为模型可以处理的数值形式。这里考虑到测试集中出现训练集中没出现过的单词，所以加入’UNK‘作为未知单词，方便处理。将训练用的句子和标签根据之前的两个字典，将文本内容转换为索引序列。

```python
class preprocess:
    def __init__(self, train_file, test_file, language):
        self.train_file = train_file
        self.test_file = test_file
        self.language = language

    def read(self):
        # 读取训练数据
        with open(self.train_file, 'r', encoding='utf-8') as f:
            train_data = f.readlines()
        # 处理训练数据
        words_train, labels_train = [[]], [[]]
        words = []
        for line in train_data:
            if line != '\n':
                word, label = line.strip().split()
                words_train[-1].append(word)
                labels_train[-1].append(label)
                words.append(word)
            else:
                words_train.append([])
                labels_train.append([])
        while [] in words_train:
            words_train.remove([])
        while [] in labels_train:
            labels_train.remove([])
        # 读取测试数据
        with open(self.test_file, 'r', encoding='utf-8') as f:
            test_data = f.readlines()
        # 处理测试数据
        words_test = [[]]
        for line in test_data:
            if(line != '\n'):
                word, label = line.strip().split()
                words_test[-1].append(word)
            else:
                words_test.append([])
        while [] in words_test:
            words_test.remove([])

        return words_train, labels_train, words_test
    
    def toidx(self, words_train, labels_train, words_test):
        # 创建单词和标签的索引
        word2idx, tag2idx = {}, {}
        for sentence, tags in zip(words_train, labels_train):
            for word, label in zip(sentence, tags):
                word2idx.setdefault(word, len(word2idx))
                tag2idx.setdefault(label, len(tag2idx))
        word2idx.setdefault('UNK', len(word2idx))
              
        # 将句子和标签转换为索引序列
        sentences_idx = [[word2idx[word] for word in sentence] for sentence in words_train]
        test_idx = [[word2idx.get(word, word2idx['UNK']) for word in sentence] for sentence in words_test]
        labels_idx = [[tag2idx[tag] for tag in tags] for tags in labels_train]
        return word2idx, tag2idx, sentences_idx, labels_idx, test_idx
```

#### 类`BiLSTM_CRF`如下：

`__init__`函数初始化定义了BiLSTM_CRF模型，该类继承自`nn.Module`类，首先调用父类的构造函数，确保正确初始化基类。然后定义了嵌入层，调用了`nn.Embedding`，定义了LSTM层，调用了`nn.LSTM`，定义了线性层，调用了`nn.Linear`，定义了CRF层，调用了`torchcrf`的`CRF。`

`forward`函数是前向函数，首先通过嵌入层，再进入LSTM层，再经过一层线性层后通过CRF层，与原有标签进行比较，得到loss。

`decode`函数是解码函数，经过训练后，将测试数据通过decode获得预测的标签。

```python
class BiLSTM_CRF(nn.Module):
    def __init__(self, vocab_size, tag2idx, embedding_dim, hidden_dim):
        super(BiLSTM_CRF, self).__init__()       
        # 嵌入层
        self.embedding = nn.Embedding(vocab_size, embedding_dim)        
        # LSTM层
        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=1, bidirectional=True)        
        # 线性层
        self.linear = nn.Linear(hidden_dim, len(tag2idx))      
        # CRF层
        self.crf = CRF(len(tag2idx))
        
    def forward(self, x, y):
        embedded = self.embedding(x)        
        lstm_out, _ = self.lstm(embedded)        
        emissions = self.linear(lstm_out)
        emissions = emissions.unsqueeze(0)  
        y = y.unsqueeze(0)  # add a new batch dimension     
        loss = -self.crf(emissions, y)        
        return loss

    
    def decode(self, x):
        embedded = self.embedding(x)       
        lstm_out, _ = self.lstm(embedded)       
        emissions = self.linear(lstm_out)
        emissions = emissions.unsqueeze(0)  # add a new batch dimension
        tags = self.crf.decode(emissions)
        return tags
```

#### 类`Trainer`如下：

`__init__`函数初始化了训练的模型，选择的优化器和损失函数，以及要选择的语言。

`train`函数为训练函数，定义了训练的轮数，将句子和对应的标签提取出来，转换成PyTorch的张量形式，对模型进行训练，进行前向反向传播并更新参数。

`test`函数为测试函数，在预测的同时将结果转换相应的文本表示，并写入文件。

```python
class Trainer:
    def __init__(self, model, optimizer, criterion, language):
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion
        self.language = language
        
    def train(self, sentences_idx, labels_idx, epochs):
        # 训练模型
        for epoch in range(epochs):
            epoch_loss = 0.0
            for sentence, tags in zip(sentences_idx, labels_idx):
                # 将句子和标签转换为PyTorch张量
                sentence = torch.tensor(sentence, dtype=torch.long)
                tags = torch.tensor(tags, dtype=torch.long)      
                # 清除之前的梯度
                self.model.zero_grad()
                # 获取模型的负对数损失
                loss = self.model(sentence, tags)
                # 反向传播并更新参数
                loss.backward()
                self.optimizer.step()
                # 累计损失
                epoch_loss += loss.item()
                
            # 打印每个训练周期的损失
            print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}")
            
    def test(self, test_idx, word2idx, tag2idx):
        # 在测试数据集上评估模型
        with torch.no_grad():
            # 将预测结果写入文件
            with open('output_'+ self.language +'_for_PJ2_3_test.txt', 'w', encoding='utf-8') as f:
                for sentence in test_idx:
                    # 将句子转换为PyTorch张量
                    sentence = torch.tensor(sentence, dtype=torch.long)
                    # 获取模型的预测标签序列
                    pred_tags = self.model.decode(sentence)
                    flat_list = [item for sublist in pred_tags for item in sublist]
                    # 将预测标签序列转换为标签
                    pred_tags = [list(tag2idx.keys())[list(tag2idx.values()).index(tag)] for tag in flat_list]
                    # 将句子转换为单词
                    words = [list(word2idx.keys())[list(word2idx.values()).index(word)] for word in sentence]
                    # 打印句子和预测标签序列
                    for i in range(len(words)):
                        f.write(words[i] + ' ' + pred_tags[i] + '\n')
                    f.write('\n')
```

#### main函数如下：

读取命令行命令

读取数据并进行预处理

定义超参数

创建模型、定义优化器和损失函数

训练模型、进行预测

```python
def main():
    # 检查命令行参数
    if len(sys.argv) != 4:
        print('Usage: python PJ2_3.py <train_file> <test_file> <language>')
        return 
    # 读取命令行参数
    train_file = sys.argv[1]
    test_file = sys.argv[2]
    language = sys.argv[3]
    # 读取数据
    print('Reading data...')
    pre = preprocess(train_file, test_file, language)
    words_train, labels_train, words_test= pre.read()
    word2idx, tag2idx, sentences_idx, labels_idx, test_idx = pre.toidx(words_train, labels_train, words_test)
    print('Reading Done!')
    # 定义超参数
    EMBEDDING_DIM = 32
    HIDDEN_DIM = 64
    EPOCHS = 20
    # 创建模型
    model = BiLSTM_CRF(len(word2idx), tag2idx, EMBEDDING_DIM, HIDDEN_DIM)
    # 定义优化器和损失函数
    optimizer = optim.Adam(model.parameters())
    criterion = nn.CrossEntropyLoss() 
    # 创建训练器
    trainer = Trainer(model, optimizer, criterion, language)
    # 训练模型
    print('Training model...')
    trainer.train(sentences_idx, labels_idx, EPOCHS)
    print('Training Done!')
    # 在测试数据集上评估模型
    print('Testing model...')
    trainer.test(test_idx, word2idx, tag2idx)
    print('Testing Done!')
```

