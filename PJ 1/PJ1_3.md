## 使用预训练模型实现MNIST手写数字分类

#### 预训练（Pre-training）+微调（Fine-tuning）

预训练：在大规模数据集上预先训练一个模型，该模型通常能学习到更多特征，在数据量或标签量不足的情况下，可以通过预训练来提高模型的泛化能力。

微调：在预训练模型的基础上，针对新的任务对模型继续训练，来适应新的数据集和任务。在面对较少数据的时候有较好效果，且训练效率更高。微调一般在预训练模型的最后加入的层上进行训练。

#### 代码和思路展示

`transform`对读入图像进行处理。这里`Lambda`是为了匹配预训练模型`resnet18`的数据输入格式，输入为三通道RGB，而MNIST数据集是单通道，故需要统一为三通道。`Normalize`对数据进行归一化，采用这个诡异的值是因为是数据集提供的超参。

```python
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.expand(3, -1, -1)),
    transforms.Normalize((0.1307,), (0.3081,))
])
```

与之前实验相同的数据读入，不过是MNIST。

```python
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
```

载入预训练模型，这里采用了`resnet18`，在该模型后加入了一个全连接层，将数据映射到0～9这十个分类中。

```python
model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)
model.fc = nn.Linear(512, 10)
```

损失函数采用了`CrossEntropyLoss`，优化器采用了`Adam`，对最后一层进行了训练。

```python
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters(), lr=0.001)
```

训练过程和之前一样，不再赘述

```python
num_epochs = 10
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)

        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i + 1) % 100 == 0:
            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
                  .format(epoch + 1, num_epochs, i + 1, len(train_loader), loss.item()))

    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)

            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        print('Test Accuracy: {:.2f}%'.format(accuracy))

torch.save(model.state_dict(), 'mnist_resnet18.pth')
```

![image-20230422104951045](/Users/xieyiweng/Library/Application Support/typora-user-images/image-20230422104951045.png)

在经过两个epoch之后准确率到达了98.92%，符合要求。